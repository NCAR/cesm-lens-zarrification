{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ref: https://github.com/NCAR/cesm-lens-aws/issues/34\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pprint\n",
    "import random\n",
    "import shutil\n",
    "from functools import reduce, partial\n",
    "from operator import mul\n",
    "\n",
    "import xarray as xr\n",
    "import yaml\n",
    "from distributed import Client\n",
    "from distributed.utils import format_bytes\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "import dask\n",
    "import intake\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from helpers import (create_grid_dataset, enforce_chunking, get_grid_vars,\n",
    "                     print_ds_info, process_variables, save_data, zarr_store, fix_time, inspect_written_stores)\n",
    "\n",
    "#dask.config.set({\"distributed.dashboard.link\": \"/proxy/{port}/status\"})\n",
    "xr.set_options(keep_attrs=True)\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = SLURMCluster(cores=8, memory=\"200GB\", processes=4)\n",
    "cluster.adapt(minimum_jobs=1, maximum_jobs=35)\n",
    "# cluster.scale(jobs=3)\n",
    "client = Client(cluster)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set to True if saving large Zarr files is resulting in KilledWorker or Dask crashes.\n",
    "# BIG_SAVE = False\n",
    "# if BIG_SAVE:\n",
    "#     min_workers = 10\n",
    "#     client.wait_for_workers(min_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's safer to use a dash '-' to separate fields, not underscores, because CESM variables have underscores.\n",
    "field_separator = \"-\"\n",
    "col = intake.open_esm_datastore(\n",
    "    \"../catalogs/glade-campaign-cesm1-le.json\", sep=field_separator,\n",
    ")\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirout = \"/glade/scratch/abanihi/data/lens-aws\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _preprocess(ds):\n",
    "    \"\"\"Drop all unnecessary variables and coordinates\"\"\"\n",
    "\n",
    "    vars_to_drop = [vname for vname in ds.data_vars if vname not in variables]\n",
    "    coord_vars = [\n",
    "        vname\n",
    "        for vname in ds.data_vars\n",
    "        if \"time\" not in ds[vname].dims or \"bound\" in vname or \"bnds\" in vname\n",
    "    ]\n",
    "    ds_fixed = ds.set_coords(coord_vars)\n",
    "    data_vars_dims = []\n",
    "    for data_var in ds_fixed.data_vars:\n",
    "        data_vars_dims.extend(list(ds_fixed[data_var].dims))\n",
    "    coords_to_drop = [\n",
    "        coord for coord in ds_fixed.coords if coord not in data_vars_dims\n",
    "    ]\n",
    "    grid_vars = list(\n",
    "        set(vars_to_drop + coords_to_drop)\n",
    "        - set([\"time\", \"time_bound\", \"time_bnds\", \"time_bounds\"])\n",
    "    )\n",
    "    ds_fixed = ds_fixed.drop(grid_vars).reset_coords()\n",
    "    if \"history\" in ds_fixed.attrs:\n",
    "        del ds_fixed.attrs[\"history\"]\n",
    "    return ds_fixed\n",
    "\n",
    "\n",
    "member_31_nh = \"/glade/campaign/cesm/collections/cesmLE/CESM-CAM5-BGC-LE/ice/proc/tseries/daily/hi_d/b.e11.B20TRC5CNBDRD.f09_g16.031.cice.h1.hi_d_nh.19200101-20051231.nc\"\n",
    "m_31_nh = xr.open_dataset(member_31_nh, chunks={})\n",
    "\n",
    "\n",
    "def _preprocess_ice_nh(ds):\n",
    "    # Fix time duplication issues in member_35_ice_nh\n",
    "    if ds.attrs[\"title\"] == \"b.e11.B20TRC5CNBDRD.f09_g16.035\":\n",
    "        attrs = ds.time.attrs\n",
    "        encoding = ds.time.encoding\n",
    "        bounds_attrs = ds.time_bounds.attrs\n",
    "        bounds_encoding = ds.time_bounds.attrs\n",
    "\n",
    "        ds = ds.assign_coords(time=m_31_nh.time)\n",
    "        ds.time_bounds.data = m_31_nh.time_bounds.data\n",
    "        ds.time.attrs, ds.time.encoding = attrs, encoding\n",
    "        ds.time_bounds.attrs, ds.time_bounds.encoding = (\n",
    "            bounds_attrs,\n",
    "            bounds_encoding,\n",
    "        )\n",
    "    return _preprocess(ds)\n",
    "\n",
    "\n",
    "member_31_sh = \"/glade/campaign/cesm/collections/cesmLE/CESM-CAM5-BGC-LE/ice/proc/tseries/daily/hi_d/b.e11.B20TRC5CNBDRD.f09_g16.031.cice.h1.hi_d_sh.19200101-20051231.nc\"\n",
    "m_31_sh = xr.open_dataset(member_31_sh, chunks={})\n",
    "\n",
    "\n",
    "def _preprocess_ice_sh(ds):\n",
    "    # Fix time duplication issues in member_35_ice_sh\n",
    "    if ds.attrs[\"title\"] == \"b.e11.B20TRC5CNBDRD.f09_g16.035\":\n",
    "        attrs = ds.time.attrs\n",
    "        encoding = ds.time.encoding\n",
    "        bounds_attrs = ds.time_bounds.attrs\n",
    "        bounds_encoding = ds.time_bounds.attrs\n",
    "\n",
    "        ds = ds.assign_coords(time=m_31_sh.time)\n",
    "        ds.time_bounds.data = m_31_sh.time_bounds.data\n",
    "        ds.time.attrs, ds.time.encoding = attrs, encoding\n",
    "        ds.time_bounds.attrs, ds.time_bounds.encoding = (\n",
    "            bounds_attrs,\n",
    "            bounds_encoding,\n",
    "        )\n",
    "    return _preprocess(ds)\n",
    "\n",
    "\n",
    "def _preprocess_lnd(ds):\n",
    "    grid = xr.open_zarr(\n",
    "        \"/glade/scratch/abanihi/data/lens-aws/lnd/static/grid.zarr\"\n",
    "    )\n",
    "    ds = ds.assign_coords(lat=grid[\"lat\"])\n",
    "    return _preprocess(ds)\n",
    "\n",
    "\n",
    "def _preprocess_atm(ds):\n",
    "    grid = xr.open_zarr(\n",
    "        \"/glade/scratch/abanihi/data/lens-aws/atm/static/grid.zarr\"\n",
    "    )\n",
    "    ds = ds.assign_coords(lat=grid[\"lat\"])\n",
    "    return _preprocess(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.yaml\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "run_config = []\n",
    "variables = []\n",
    "\n",
    "for component, stream_val in config.items():\n",
    "    for stream, v in stream_val.items():\n",
    "        frequency = v[\"frequency\"]\n",
    "        freq = v[\"freq\"]\n",
    "        time_bounds_dim = v[\"time_bounds_dim\"]\n",
    "        variable_categories = list(v[\"variable_category\"].keys())\n",
    "        for v_cat in variable_categories:\n",
    "            experiments = list(\n",
    "                v[\"variable_category\"][v_cat][\"experiment\"].keys()\n",
    "            )\n",
    "            for exp in experiments:\n",
    "                if frequency == \"daily\" and exp == \"20C\" and component == \"atm\":\n",
    "                    # date_ranges = ['1990010100Z-2005123118Z', '2026010100Z-2035123118Z', '2071010100Z-2080123118Z']\n",
    "                    chunks = v[\"variable_category\"][v_cat][\"experiment\"][exp][\n",
    "                        \"chunks\"\n",
    "                    ]\n",
    "                    variable = v[\"variable_category\"][v_cat][\"variable\"]\n",
    "                    variables.extend(variable)\n",
    "                    col_subset, query = process_variables(\n",
    "                        col, variable, component, stream, exp\n",
    "                    )\n",
    "                    if not col_subset.df.empty:\n",
    "                        d = {\n",
    "                            \"query\": query,\n",
    "                            \"col\": col_subset,\n",
    "                            \"chunks\": chunks,\n",
    "                            \"frequency\": frequency,\n",
    "                            \"freq\": freq,\n",
    "                            \"time_bounds_dim\": time_bounds_dim,\n",
    "                        }\n",
    "                        run_config.append(d)\n",
    "run_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for run in tqdm(run_config, desc=\"runs\"):\n",
    "    print(\"*\" * 120)\n",
    "    query = run[\"query\"]\n",
    "    print(f\"query = {query}\")\n",
    "    frequency = run[\"frequency\"]\n",
    "    chunks = run[\"chunks\"]\n",
    "    freq = run[\"freq\"]\n",
    "    time_bounds_dim = run[\"time_bounds_dim\"]\n",
    "    preprocess = _preprocess\n",
    "    if query[\"experiment\"] == \"20C\" and query[\"stream\"] == \"cice.h1\":\n",
    "        if query[\"component\"] == \"ice_sh\":\n",
    "            preprocess = _preprocess_ice_sh\n",
    "        elif query[\"component\"] == \"ice_nh\":\n",
    "            preprocess = _preprocess_ice_nh\n",
    "    elif query[\"component\"] == \"lnd\":\n",
    "        preprocess = _preprocess_lnd\n",
    "    elif query[\"component\"] == \"atm\":\n",
    "        preprocess = _preprocess_atm\n",
    "\n",
    "    print(preprocess.__name__)\n",
    "\n",
    "    dsets = run[\"col\"].to_dataset_dict(\n",
    "        cdf_kwargs={\"chunks\": chunks, \"decode_times\": True, \"use_cftime\": True},\n",
    "        preprocess=preprocess,\n",
    "        progressbar=True,\n",
    "    )\n",
    "    dsets = enforce_chunking(dsets, chunks, field_separator)\n",
    "    for key, ds in tqdm(dsets.items(), desc=\"Saving zarr store\"):\n",
    "        print(ds.get_index(\"time\").is_monotonic_increasing)\n",
    "        key = key.split(field_separator)\n",
    "        exp, cmp, var, frequency = key[1], key[0], key[-1], frequency\n",
    "        if frequency != \"hourly6\":\n",
    "            if exp == \"20C\":\n",
    "                start = \"1850-01\"\n",
    "                end = \"2006-01\"\n",
    "                if frequency == \"monthly\":\n",
    "                    ds = fix_time(\n",
    "                        ds,\n",
    "                        start=start,\n",
    "                        end=end,\n",
    "                        freq=freq,\n",
    "                        time_bounds_dim=time_bounds_dim,\n",
    "                    )\n",
    "                else:\n",
    "                    ds = fix_time(\n",
    "                        ds,\n",
    "                        start=None,\n",
    "                        end=None,\n",
    "                        freq=None,\n",
    "                        time_bounds_dim=time_bounds_dim,\n",
    "                        generate_bounds=False,\n",
    "                    )\n",
    "                ds_20c = ds.sel(time=slice(\"1920\", None)).chunk(chunks)\n",
    "                store = zarr_store(\n",
    "                    exp, cmp, frequency, var, write=False, dirout=dirout\n",
    "                )\n",
    "                save_data(ds_20c, store)\n",
    "                ds_hist = ds.sel(time=slice(None, \"1919\"), member_id=1).chunk(\n",
    "                    chunks\n",
    "                )\n",
    "                exp = \"HIST\"\n",
    "                store = zarr_store(\n",
    "                    exp, cmp, frequency, var, write=False, dirout=dirout\n",
    "                )\n",
    "                save_data(ds_hist, store)\n",
    "\n",
    "            elif exp == \"RCP85\":\n",
    "                start = \"2006-01\"\n",
    "                end = \"2101-01\"\n",
    "                if frequency == \"monthly\":\n",
    "                    ds = fix_time(\n",
    "                        ds,\n",
    "                        start=start,\n",
    "                        end=end,\n",
    "                        freq=freq,\n",
    "                        time_bounds_dim=time_bounds_dim,\n",
    "                    )\n",
    "                else:\n",
    "                    ds = fix_time(\n",
    "                        ds,\n",
    "                        start=None,\n",
    "                        end=None,\n",
    "                        freq=None,\n",
    "                        time_bounds_dim=time_bounds_dim,\n",
    "                        generate_bounds=False,\n",
    "                    )\n",
    "                store = zarr_store(\n",
    "                    exp, cmp, frequency, var, write=False, dirout=dirout\n",
    "                )\n",
    "                save_data(ds, store)\n",
    "\n",
    "            elif exp == \"CTRL\":\n",
    "                ds = fix_time(\n",
    "                    ds,\n",
    "                    start=None,\n",
    "                    end=None,\n",
    "                    freq=None,\n",
    "                    time_bounds_dim=time_bounds_dim,\n",
    "                    generate_bounds=False,\n",
    "                )\n",
    "                store = zarr_store(\n",
    "                    exp, cmp, frequency, var, write=False, dirout=dirout\n",
    "                )\n",
    "                save_data(ds, store)\n",
    "        else:\n",
    "            if exp == \"20C\":\n",
    "                start = \"1990\"\n",
    "                end = \"2006-01-01T06:00\"\n",
    "                ds = fix_time(\n",
    "                    ds,\n",
    "                    start=start,\n",
    "                    end=end,\n",
    "                    freq=freq,\n",
    "                    time_bounds_dim=time_bounds_dim,\n",
    "                    instantaneous=True,\n",
    "                )\n",
    "                frequency_x = f\"{frequency}-1990-2005\"\n",
    "                store = zarr_store(\n",
    "                    exp, cmp, frequency_x, var, write=False, dirout=dirout\n",
    "                )\n",
    "                save_data(ds, store)\n",
    "\n",
    "            elif exp == \"RCP85\":\n",
    "                frequency_x = f\"{frequency}-2026-2035\"\n",
    "                ds_1 = ds.sel(time=slice(None, \"2036\"))\n",
    "                start = \"2026\"\n",
    "                end = \"2036-01-01T06:00\"\n",
    "                ds_1 = fix_time(\n",
    "                    ds_1,\n",
    "                    start=start,\n",
    "                    end=end,\n",
    "                    freq=freq,\n",
    "                    time_bounds_dim=time_bounds_dim,\n",
    "                    instantaneous=True,\n",
    "                ).chunk(chunks)\n",
    "                store_1 = zarr_store(\n",
    "                    exp, cmp, frequency_x, var, write=False, dirout=dirout\n",
    "                )\n",
    "\n",
    "                frequency_x = f\"{frequency}-2071-2080\"\n",
    "                start = \"2071\"\n",
    "                end = \"2081-01-01T06:00\"\n",
    "                ds_2 = ds.sel(time=slice(\"2071\", None))\n",
    "                ds_2 = fix_time(\n",
    "                    ds_2,\n",
    "                    start=start,\n",
    "                    end=end,\n",
    "                    freq=freq,\n",
    "                    time_bounds_dim=time_bounds_dim,\n",
    "                    instantaneous=True,\n",
    "                ).chunk(chunks)\n",
    "                store_2 = zarr_store(\n",
    "                    exp, cmp, frequency_x, var, write=False, dirout=dirout\n",
    "                )\n",
    "\n",
    "                assert ds.time.size == (ds_1.time.size + ds_2.time.size)\n",
    "                save_data(ds_1, store_1)\n",
    "                save_data(ds_2, store_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_hist.time, ds_20c.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the zarr stores were properly written\n",
    "\n",
    "inspect_written_stores(dirout, random_sample_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext watermark\n",
    "# %watermark -d -iv -m -g -h"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
