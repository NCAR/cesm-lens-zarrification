{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ref: https://github.com/NCAR/cesm-lens-aws/issues/34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pprint\n",
    "import random\n",
    "import shutil\n",
    "from functools import reduce\n",
    "from operator import mul\n",
    "\n",
    "import xarray as xr\n",
    "import yaml\n",
    "from distributed import Client\n",
    "from distributed.utils import format_bytes\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import dask\n",
    "import intake\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from helpers import (create_grid_dataset, enforce_chunking, get_grid_vars,\n",
    "                     print_ds_info, process_variables, save_data, zarr_store)\n",
    "\n",
    "dask.config.set({\"distributed.dashboard.link\": \"/proxy/{port}/status\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = SLURMCluster(cores=4, memory=\"200GB\")\n",
    "cluster.adapt(minimum_jobs=0, maximum_jobs=35)\n",
    "# cluster.scale(jobs=3)\n",
    "client = Client(cluster)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set to True if saving large Zarr files is resulting in KilledWorker or Dask crashes.\n",
    "BIG_SAVE = False\n",
    "if BIG_SAVE:\n",
    "    min_workers = 10\n",
    "    client.wait_for_workers(min_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's safer to use a dash '-' to separate fields, not underscores, because CESM variables have underscores.\n",
    "field_separator = \"-\"\n",
    "col = intake.open_esm_datastore(\n",
    "    \"../catalogs/glade-campaign-cesm1-le.json\", sep=field_separator,\n",
    ")\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _preprocess(ds):\n",
    "    \"\"\"Drop all unnecessary variables and coordinates\"\"\"\n",
    "    grid_vars = get_grid_vars(ds, variables)\n",
    "    ds_fixed = ds.drop(grid_vars)\n",
    "    if \"history\" in ds_fixed.attrs:\n",
    "        del ds_fixed.attrs[\"history\"]\n",
    "    return ds_fixed\n",
    "\n",
    "\n",
    "def _preprocess_ice_nh(ds):\n",
    "    member_31 = \"/glade/campaign/cesm/collections/cesmLE/CESM-CAM5-BGC-LE/ice/proc/tseries/daily/hi_d/b.e11.B20TRC5CNBDRD.f09_g16.031.cice.h1.hi_d_nh.19200101-20051231.nc\"\n",
    "    m_31 = xr.open_dataset(member_31, chunks={\"time\": 2}, decode_times=False)\n",
    "\n",
    "    # Fix some issues in member_35_ice_nh\n",
    "    if ds.time.min() == 0:\n",
    "        ds = ds.assign(time=m_31.time)\n",
    "\n",
    "    return _preprocess(ds)\n",
    "\n",
    "\n",
    "def _preprocess_ice_sh(ds):\n",
    "    member_31 = \"/glade/campaign/cesm/collections/cesmLE/CESM-CAM5-BGC-LE/ice/proc/tseries/daily/hi_d/b.e11.B20TRC5CNBDRD.f09_g16.031.cice.h1.hi_d_sh.19200101-20051231.nc\"\n",
    "    m_31 = xr.open_dataset(member_31, chunks={\"time\": 2}, decode_times=False)\n",
    "\n",
    "    # Fix some issues in member_35_ice_sh\n",
    "    if ds.time.min() == 0:\n",
    "        ds = ds.assign(time=m_31.time)\n",
    "\n",
    "    return _preprocess(ds)\n",
    "\n",
    "\n",
    "def _preprocess_lnd(ds):\n",
    "    path = \"/glade/campaign/cesm/collections/cesmLE/CESM-CAM5-BGC-LE/lnd/proc/tseries/daily/FSNO/b.e11.BRCP85C5CNBDRD.f09_g16.001.clm2.h1.FSNO.20060101-20801231.nc\"\n",
    "    lnd_grid = create_grid_dataset(path, variables=[\"FSNO\"])\n",
    "    ds = ds.assign(lat=lnd_grid.lat)\n",
    "    return _preprocess(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.yaml\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "run_config = []\n",
    "variables = []\n",
    "\n",
    "for component, stream_val in config.items():\n",
    "    for stream, v in stream_val.items():\n",
    "        frequency = v[\"frequency\"]\n",
    "        variable_categories = list(v[\"variable_category\"].keys())\n",
    "        for v_cat in variable_categories:\n",
    "            experiments = list(\n",
    "                v[\"variable_category\"][v_cat][\"experiment\"].keys()\n",
    "            )\n",
    "            for exp in experiments:\n",
    "                chunks = v[\"variable_category\"][v_cat][\"experiment\"][exp][\n",
    "                    \"chunks\"\n",
    "                ]\n",
    "                variable = v[\"variable_category\"][v_cat][\"variable\"]\n",
    "                variables.extend(variable)\n",
    "                col_subset, query = process_variables(\n",
    "                    col, variable, component, stream, exp\n",
    "                )\n",
    "                if not col_subset.df.empty:\n",
    "                    d = {\n",
    "                        \"query\": query,\n",
    "                        \"col\": col_subset,\n",
    "                        \"chunks\": chunks,\n",
    "                        \"frequency\": frequency,\n",
    "                    }\n",
    "                    run_config.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirout = \"/glade/scratch/abanihi/lens-aws\"\n",
    "\n",
    "for run in run_config:\n",
    "    print(\"*\" * 120)\n",
    "    query = run[\"query\"]\n",
    "    print(f\"query = {query}\")\n",
    "    frequency = run[\"frequency\"]\n",
    "    chunks = run[\"chunks\"]\n",
    "    preprocess = _preprocess\n",
    "    if query[\"experiment\"] == \"20C\" and query[\"stream\"] == \"cice.h1\":\n",
    "        if query[\"component\"] == \"ice_sh\":\n",
    "            preprocess = _preprocess_ice_sh\n",
    "        elif query[\"component\"] == \"ice_nh\":\n",
    "            preprocess = _preprocess_ice_sh\n",
    "\n",
    "    if query[\"experiment\"] == \"RCP85\" and query[\"stream\"] == \"clm2.h1\":\n",
    "        preprocess = _preprocess_lnd\n",
    "\n",
    "    print(f\"using preprocess={preprocess.__name__}\")\n",
    "    dsets = run[\"col\"].to_dataset_dict(\n",
    "        cdf_kwargs={\"chunks\": chunks, \"decode_times\": False},\n",
    "        preprocess=preprocess,\n",
    "        progressbar=False,\n",
    "    )\n",
    "    dsets = enforce_chunking(dsets, chunks, field_separator)\n",
    "    for key, ds in tqdm(dsets.items(), desc=\"Saving zarr store\"):\n",
    "        key = key.split(field_separator)\n",
    "        exp, cmp, var, frequency = key[1], key[0], key[-1], frequency\n",
    "        store = zarr_store(exp, cmp, frequency, var, write=True, dirout=dirout)\n",
    "        save_data(ds, store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the zarr stores were properly written\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "p = Path(dirout) / \"lnd\"\n",
    "stores = list(p.rglob(\"*.zarr\"))\n",
    "for store in stores:\n",
    "    try:\n",
    "        ds = xr.open_zarr(store.as_posix(), consolidated=True)\n",
    "        print(\"\\n\")\n",
    "        print(store)\n",
    "        print(ds)\n",
    "    except Exception as e:\n",
    "        # print(e)\n",
    "        print(store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext watermark\n",
    "# %watermark -d -iv -m -g -h"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
