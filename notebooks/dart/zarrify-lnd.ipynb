{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zarrify DART Reanalysis History Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import intake\n",
    "import ast\n",
    "import pandas as pd\n",
    "from helpers import update_metadata\n",
    "\n",
    "import dask\n",
    "import dask.distributed\n",
    "from dask.distributed import Client\n",
    "from ncar_jobqueue import NCARCluster\n",
    "from distributed.utils import format_bytes\n",
    "\n",
    "import fsspec\n",
    "from pathlib import Path\n",
    "import shutil \n",
    "import os\n",
    "from functools import reduce\n",
    "from operator import mul"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog_path = './dart-zarr-input.json'\n",
    "\n",
    "output_folder = '/glade/scratch/bonnland/DART/ds345.0/zarr-publish'\n",
    "\n",
    "#output_variables = ['T', 'PS', 'Q', 'US', 'VS', 'CLDICE', 'CLDLIQ']\n",
    "\n",
    "#output_variables = ['TSA', 'ER', 'EFLX_LH_TOT', 'HR']\n",
    "output_variables = ['ER', 'EFLX_LH_TOT', 'HR']\n",
    "\n",
    "# Number of elements per chunk in the target stores.\n",
    "# A negative value means \"don't chunk this dimension\".\n",
    "#target_chunks = {'pftlat': 32, \n",
    "#                 'pftlon': 32, \n",
    "#                 'time': 30, \n",
    "#                 'member_id': 10}\n",
    "\n",
    "target_chunks = {'lat': 32, \n",
    "                 'lon': 32, \n",
    "                 'time': 200, \n",
    "                 'member_id': 40}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Run These Cells for Dask CASPER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33ad2e93f8dd400e8aff3f6338d97e72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>PBSCluster</h2>'), HBox(children=(HTML(value='\\n<div>\\n  <style scoped>\\n    .dâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Processes is processes PER CORE.\n",
    "# This one works fine.\n",
    "#cluster = NCARCluster(cores=15, processes=1, memory='100GB', project='STDD0003')\n",
    "# This one also works, but occasionally hangs neacr the end.\n",
    "#cluster = NCARCluster(cores=10, processes=1, memory='50GB', project='STDD0003')\n",
    "\n",
    "# For Casper\n",
    "num_cores = 2 #1\n",
    "num_jobs = 50 #90 #4\n",
    "walltime = \"1:00:00\" #\"1:00:00\"\n",
    "memory = '50GB' #'50GB'\n",
    "\n",
    "cluster = NCARCluster(cores=num_cores, processes=1, memory=memory, project='STDD0003', walltime=walltime)\n",
    "cluster.scale(jobs=num_jobs)\n",
    "\n",
    "client = Client(cluster)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Run These Cells for Dask CHEYENNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For Cheyenne\n",
    "\n",
    "# These are \"per node\", and then .scale() selects the number of nodes.\n",
    "#walltime = \"1:00:00\"\n",
    "#walltime = \"00:30:00\"\n",
    "walltime = \"00:45:00\"\n",
    "\n",
    "#  This results in about 20% maximum memory usage.\n",
    "#cluster = NCARCluster(cores=1, processes=1, memory='109GB', walltime=walltime)\n",
    "#num_nodes = 16\n",
    "\n",
    "\n",
    "# Run 16 workers on 4 nodes, giving each worker around 25GB RAM.  \n",
    "#cluster = NCARCluster(cores=4, processes=4, memory='109GB', walltime=walltime)\n",
    "\n",
    "# # Run 4 workers on each node, giving each worker around 25GB RAM.  \n",
    "# cluster = NCARCluster(cores=16, processes=4, memory='109GB', walltime=walltime)\n",
    "# num_nodes = 2\n",
    "\n",
    "# Run <= 4 workers on each node to avoid crashes.\n",
    "cluster = NCARCluster(cores=10, processes=4, memory='109GB', walltime=walltime)\n",
    "num_nodes = 8\n",
    "\n",
    "cluster.scale(jobs=num_nodes)\n",
    "\n",
    "from distributed import Client\n",
    "from distributed.utils import format_bytes\n",
    "client = Client(cluster)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zarr-related Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Preprocessing Steps for each input dataset before merge\n",
    "def preprocess_sparse(ds):\n",
    "    \"\"\"Pare down each input dataset to a single variable.  \n",
    "       The subsequent merge will eliminate unused coordinates automatically. \n",
    "        \n",
    "        This function does not allow additional arguments, so the target \n",
    "        output variable needs to be defined globally in TARGET_VAR.\n",
    "    \"\"\"\n",
    "    drop_vars = [var for var in ds.data_vars \n",
    "                 if var != TARGET_VAR]\n",
    "\n",
    "    ds_fixed = ds.drop_vars(drop_vars)\n",
    "    \n",
    "    lats = list(ds.pfts1d_lat.astype('float32').data)\n",
    "    lons = list(ds.pfts1d_lon.astype('float32').data)\n",
    "    vegtype = list(ds.pfts1d_itype_veg.data)\n",
    "    coltype = list(ds.pfts1d_itype_col.data)\n",
    "    lunittype = list(ds.pfts1d_itype_lunit.data)\n",
    "    active = list(ds.pfts1d_active.data)\n",
    "    \n",
    "    # Redefine the 'pft' dimension as a multi-index, which will increase the number of dimensions.\n",
    "    #arrays = [list(lats.data), list(lons.data), list(vegtype.data), list(coltype.data), list(lunittype.data, active.data]\n",
    "    #dim_names = ('pftlat', 'pftlon', 'vegtype', 'coltype', 'lunittype', 'active')\n",
    "    index = pd.MultiIndex.from_arrays([lats, lons, vegtype, coltype, lunittype, active], \n",
    "                                  names=('pftlat', 'pftlon', 'vegtype', 'coltype', 'lunittype', 'active'))\n",
    "    ds_fixed['pft'] = index\n",
    "\n",
    "    \n",
    "    # Keep the data sparse if possible to avoid memory shortages.\n",
    "    ds_fixed = ds_fixed.unstack(sparse=True)\n",
    "    return ds_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Preprocessing Steps for each input dataset before merge\n",
    "def preprocess(ds):\n",
    "    \"\"\"Pare down each input dataset to a single variable.  \n",
    "       The subsequent merge will eliminate unused coordinates automatically. \n",
    "        \n",
    "        This function does not allow additional arguments, so the target \n",
    "        output variable needs to be defined globally in TARGET_VAR.\n",
    "    \"\"\"\n",
    "    drop_vars = [var for var in ds.data_vars \n",
    "                 if var != TARGET_VAR]\n",
    "\n",
    "    ds_fixed = ds.drop_vars(drop_vars)\n",
    "    \n",
    "    # Drop these unused dimensions if they exist.\n",
    "    drop_dims = ['levlak', 'levgrnd', 'levdcmp']\n",
    "    to_drop = [d for d in drop_dims if d in ds_fixed.dims]\n",
    "    ds_fixed = ds_fixed.drop_dims(to_drop)\n",
    "\n",
    "    return ds_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_ds_info(ds, var):\n",
    "    \"\"\"Function for printing chunking information\"\"\"\n",
    "\n",
    "    print(f'print_ds_info: var == {var}')\n",
    "    dt = ds[var].dtype\n",
    "    itemsize = dt.itemsize\n",
    "    chunk_size = ds[var].data.chunksize\n",
    "    size = format_bytes(ds.nbytes)\n",
    "    _bytes = reduce(mul, chunk_size) * itemsize\n",
    "    chunk_size_bytes = format_bytes(_bytes)\n",
    "\n",
    "    print(f'Variable name: {var}')\n",
    "    print(f'Dataset dimensions: {ds[var].dims}')\n",
    "    print(f'Chunk shape: {chunk_size}')\n",
    "    print(f'Dataset shape: {ds[var].shape}')\n",
    "    print(f'Chunk size: {chunk_size_bytes}')\n",
    "    print(f'Dataset size: {size}')\n",
    "\n",
    "    \n",
    "def zarr_store(var, dirout, write=False):\n",
    "    \"\"\" Create zarr store name/path\n",
    "    \"\"\"\n",
    "    path = f'{dirout}/{var}.zarr'\n",
    "    if write and os.path.exists(path):\n",
    "        shutil.rmtree(path)\n",
    "    print(path)\n",
    "    return path\n",
    "\n",
    "\n",
    "def save_data(ds, store):\n",
    "    try:\n",
    "        ds.to_zarr(store=store, consolidated=True)\n",
    "        del ds\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to write {store}: {e}\")\n",
    "\n",
    "        \n",
    "def zarr_check():\n",
    "    '''Make sure the zarr stores were properly written'''\n",
    "\n",
    "    from pathlib import Path\n",
    "    p = Path(output_folder)\n",
    "    stores = list(p.rglob(\"*.zarr\"))\n",
    "    #stores = list(p.rglob(\"*.rcp45.day.NAM-22i.raw.zarr\"))\n",
    "    for store in stores:\n",
    "        try:\n",
    "            ds = xr.open_zarr(store.as_posix(), consolidated=True)\n",
    "            print('\\n')\n",
    "            print(store)\n",
    "            print(ds)\n",
    "        except Exception as e:\n",
    "            #print(e)\n",
    "            print(store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong>dart-zarr-input catalog with 4 dataset(s) from 320 asset(s)</strong>:</p> <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>variable</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>member_id</th>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>path</th>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Open catalog with single-valued \"variable\" column\n",
    "\n",
    "# Have the catalog interpret the \"variable\" column as a list of values.\n",
    "col = intake.open_esm_datastore(catalog_path)\n",
    "col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eventual store base names:\n",
      "dict_keys(['EFLX_LH_TOT', 'ER', 'HR', 'TSA'])\n"
     ]
    }
   ],
   "source": [
    "# Show the eventual output store base names.\n",
    "print(\"Eventual store base names:\")\n",
    "print(col.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'variable'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1/1 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print_ds_info: var == ER\n",
      "Variable name: ER\n",
      "Dataset dimensions: ('member_id', 'time', 'lat', 'lon')\n",
      "Chunk shape: (40, 200, 32, 32)\n",
      "Dataset shape: (80, 11687, 192, 288)\n",
      "Chunk size: 31.25 MiB\n",
      "Dataset size: 192.60 GiB\n",
      "/glade/scratch/bonnland/DART/ds345.0/zarr-publish/ER.zarr\n",
      "     ... Done.\n",
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'variable'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1/1 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print_ds_info: var == EFLX_LH_TOT\n",
      "Variable name: EFLX_LH_TOT\n",
      "Dataset dimensions: ('member_id', 'time', 'lat', 'lon')\n",
      "Chunk shape: (40, 200, 32, 32)\n",
      "Dataset shape: (80, 11687, 192, 288)\n",
      "Chunk size: 31.25 MiB\n",
      "Dataset size: 192.60 GiB\n",
      "/glade/scratch/bonnland/DART/ds345.0/zarr-publish/EFLX_LH_TOT.zarr\n",
      "     ... Done.\n",
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'variable'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1/1 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print_ds_info: var == HR\n",
      "Variable name: HR\n",
      "Dataset dimensions: ('member_id', 'time', 'lat', 'lon')\n",
      "Chunk shape: (40, 200, 32, 32)\n",
      "Dataset shape: (80, 11687, 192, 288)\n",
      "Chunk size: 31.25 MiB\n",
      "Dataset size: 192.60 GiB\n",
      "/glade/scratch/bonnland/DART/ds345.0/zarr-publish/HR.zarr\n",
      "     ... Done.\n"
     ]
    }
   ],
   "source": [
    "REALLY_SAVE = True\n",
    "\n",
    "for variable in output_variables:\n",
    "    # This variable gets used in the \"preprocess\" function and must be defined now in the global scope.\n",
    "    TARGET_VAR = variable\n",
    "\n",
    "    col_subset = col.search(variable = variable)\n",
    "    # Produce var-based stores.  The catalog will determine how many stores and their base names.\n",
    "    with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
    "        dsets = col_subset.to_dataset_dict(zarr_kwargs={'consolidated': True}, preprocess=preprocess)\n",
    "\n",
    "    ds_out = dsets[variable]\n",
    "    \n",
    "    # Specify final chunking.\n",
    "    ds_out = ds_out.chunk(target_chunks)\n",
    "\n",
    "    # Update store metadata\n",
    "    ds_out.attrs = update_metadata(ds_out.attrs)\n",
    "\n",
    "    \n",
    "    # Confirm output contents.\n",
    "    print_ds_info(ds_out, variable)\n",
    "    \n",
    "    \n",
    "    store = zarr_store(variable, dirout = output_folder, write=REALLY_SAVE)\n",
    "    if REALLY_SAVE:\n",
    "        save_data(ds_out, store=store)\n",
    "        print(\"     ... Done.\")\n",
    "    else:\n",
    "        print(\"     ... (Skipping)\")\n",
    "        del ds_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "/glade/scratch/bonnland/DART/ds345.0/zarr-publish/HR.zarr\n",
      "<xarray.Dataset>\n",
      "Dimensions:    (lat: 192, lon: 288, member_id: 80, time: 11687)\n",
      "Coordinates:\n",
      "  * lat        (lat) float32 -90.0 -89.06 -88.12 -87.17 ... 88.12 89.06 90.0\n",
      "  * lon        (lon) float32 0.0 1.25 2.5 3.75 5.0 ... 355.0 356.2 357.5 358.8\n",
      "  * member_id  (member_id) int64 1 2 3 4 5 6 7 8 9 ... 73 74 75 76 77 78 79 80\n",
      "  * time       (time) datetime64[ns] 2012-01-01T06:00:00 ... 2019-12-31T18:00:00\n",
      "Data variables:\n",
      "    HR         (member_id, time, lat, lon) float32 dask.array<chunksize=(40, 200, 32, 32), meta=np.ndarray>\n",
      "Attributes: (12/16)\n",
      "    Initial_conditions_dataset:           f.e21.FHIST_BGC.f09_025.CAM6assim.0...\n",
      "    PFT_physiological_constants_dataset:  clm5_params.c171117.nc\n",
      "    Surface_dataset:                      surfdata_0.9x1.25_78pfts_CMIP6_simy...\n",
      "    case_id:                              f.e21.FHIST_BGC.f09_025.CAM6assim.011\n",
      "    cft:                                  {\"cft_tropical_soybean\": 63, \"cft_i...\n",
      "    comment:                              NOTE: None of the variables are wei...\n",
      "    ...                                   ...\n",
      "    institution_id:                       NCAR RDA\n",
      "    ltype:                                {\"ltype_UNUSED\": 3, \"ltype_landice_...\n",
      "    source:                               Community Land Model CLM4.0\n",
      "    time_period_freq:                     hour_6\n",
      "    version:                              release-cesm2.1.0-1-gdab62ed\n",
      "    zarr-version:                         1.0\n",
      "\n",
      "\n",
      "/glade/scratch/bonnland/DART/ds345.0/zarr-publish/VS.zarr\n",
      "<xarray.Dataset>\n",
      "Dimensions:    (ilev: 33, lat: 192, lev: 32, lon: 288, member_id: 80, slat: 191, slon: 288, time: 685)\n",
      "Coordinates:\n",
      "  * ilev       (ilev) float32 2.255 5.032 10.16 18.56 ... 967.5 985.1 1e+03\n",
      "  * lat        (lat) float32 -90.0 -89.06 -88.12 -87.17 ... 88.12 89.06 90.0\n",
      "  * lev        (lev) float32 3.643 7.595 14.36 24.61 ... 936.2 957.5 976.3 992.6\n",
      "  * lon        (lon) float32 0.0 1.25 2.5 3.75 5.0 ... 355.0 356.2 357.5 358.8\n",
      "  * member_id  (member_id) int64 1 2 3 4 5 6 7 8 9 ... 73 74 75 76 77 78 79 80\n",
      "  * slat       (slat) float32 -89.53 -88.59 -87.64 -86.7 ... 87.64 88.59 89.53\n",
      "  * slon       (slon) float32 -0.625 0.625 1.875 3.125 ... 355.6 356.9 358.1\n",
      "  * time       (time) datetime64[ns] 2011-01-03 ... 2019-12-31T18:00:00\n",
      "Data variables:\n",
      "    VS         (member_id, time, lev, lat, slon) float64 dask.array<chunksize=(10, 30, 32, 32, 32), meta=np.ndarray>\n",
      "Attributes:\n",
      "    creation_date:   YYYY MM DD HH MM SS = 2019 07 10 01 31 17\n",
      "    model:           CAM\n",
      "    model_revdate:   $Date: 2019-03-26 09:18:06 -0600 (Tue, 26 Mar 2019) $\n",
      "    model_revision:  $Revision: 13074 $\n",
      "    dataset_id:      ds345.0\n",
      "    dataset_title:   DART Reanalysis\n",
      "    experiment_id:   Reanalysis\n",
      "    institution_id:  NCAR RDA\n",
      "    zarr-version:    1.0\n",
      "\n",
      "\n",
      "/glade/scratch/bonnland/DART/ds345.0/zarr-publish/PS.zarr\n",
      "<xarray.Dataset>\n",
      "Dimensions:    (ilev: 33, lat: 192, lev: 32, lon: 288, member_id: 80, slat: 191, slon: 288, time: 685)\n",
      "Coordinates:\n",
      "  * ilev       (ilev) float32 2.255 5.032 10.16 18.56 ... 967.5 985.1 1e+03\n",
      "  * lat        (lat) float32 -90.0 -89.06 -88.12 -87.17 ... 88.12 89.06 90.0\n",
      "  * lev        (lev) float32 3.643 7.595 14.36 24.61 ... 936.2 957.5 976.3 992.6\n",
      "  * lon        (lon) float32 0.0 1.25 2.5 3.75 5.0 ... 355.0 356.2 357.5 358.8\n",
      "  * member_id  (member_id) int64 1 2 3 4 5 6 7 8 9 ... 73 74 75 76 77 78 79 80\n",
      "  * slat       (slat) float32 -89.53 -88.59 -87.64 -86.7 ... 87.64 88.59 89.53\n",
      "  * slon       (slon) float32 -0.625 0.625 1.875 3.125 ... 355.6 356.9 358.1\n",
      "  * time       (time) datetime64[ns] 2011-01-03 ... 2019-12-31T18:00:00\n",
      "Data variables:\n",
      "    PS         (member_id, time, lat, lon) float64 dask.array<chunksize=(10, 30, 32, 32), meta=np.ndarray>\n",
      "Attributes:\n",
      "    creation_date:   YYYY MM DD HH MM SS = 2019 07 10 01 31 17\n",
      "    model:           CAM\n",
      "    model_revdate:   $Date: 2019-03-26 09:18:06 -0600 (Tue, 26 Mar 2019) $\n",
      "    model_revision:  $Revision: 13074 $\n",
      "    dataset_id:      ds345.0\n",
      "    dataset_title:   DART Reanalysis\n",
      "    experiment_id:   Reanalysis\n",
      "    institution_id:  NCAR RDA\n",
      "    zarr-version:    1.0\n",
      "\n",
      "\n",
      "/glade/scratch/bonnland/DART/ds345.0/zarr-publish/Q.zarr\n",
      "<xarray.Dataset>\n",
      "Dimensions:    (ilev: 33, lat: 192, lev: 32, lon: 288, member_id: 80, slat: 191, slon: 288, time: 685)\n",
      "Coordinates:\n",
      "  * ilev       (ilev) float32 2.255 5.032 10.16 18.56 ... 967.5 985.1 1e+03\n",
      "  * lat        (lat) float32 -90.0 -89.06 -88.12 -87.17 ... 88.12 89.06 90.0\n",
      "  * lev        (lev) float32 3.643 7.595 14.36 24.61 ... 936.2 957.5 976.3 992.6\n",
      "  * lon        (lon) float32 0.0 1.25 2.5 3.75 5.0 ... 355.0 356.2 357.5 358.8\n",
      "  * member_id  (member_id) int64 1 2 3 4 5 6 7 8 9 ... 73 74 75 76 77 78 79 80\n",
      "  * slat       (slat) float32 -89.53 -88.59 -87.64 -86.7 ... 87.64 88.59 89.53\n",
      "  * slon       (slon) float32 -0.625 0.625 1.875 3.125 ... 355.6 356.9 358.1\n",
      "  * time       (time) datetime64[ns] 2011-01-03 ... 2019-12-31T18:00:00\n",
      "Data variables:\n",
      "    Q          (member_id, time, lev, lat, lon) float64 dask.array<chunksize=(10, 30, 32, 32, 32), meta=np.ndarray>\n",
      "Attributes:\n",
      "    creation_date:   YYYY MM DD HH MM SS = 2019 07 10 01 31 17\n",
      "    model:           CAM\n",
      "    model_revdate:   $Date: 2019-03-26 09:18:06 -0600 (Tue, 26 Mar 2019) $\n",
      "    model_revision:  $Revision: 13074 $\n",
      "    dataset_id:      ds345.0\n",
      "    dataset_title:   DART Reanalysis\n",
      "    experiment_id:   Reanalysis\n",
      "    institution_id:  NCAR RDA\n",
      "    zarr-version:    1.0\n",
      "\n",
      "\n",
      "/glade/scratch/bonnland/DART/ds345.0/zarr-publish/US.zarr\n",
      "<xarray.Dataset>\n",
      "Dimensions:    (ilev: 33, lat: 192, lev: 32, lon: 288, member_id: 80, slat: 191, slon: 288, time: 685)\n",
      "Coordinates:\n",
      "  * ilev       (ilev) float32 2.255 5.032 10.16 18.56 ... 967.5 985.1 1e+03\n",
      "  * lat        (lat) float32 -90.0 -89.06 -88.12 -87.17 ... 88.12 89.06 90.0\n",
      "  * lev        (lev) float32 3.643 7.595 14.36 24.61 ... 936.2 957.5 976.3 992.6\n",
      "  * lon        (lon) float32 0.0 1.25 2.5 3.75 5.0 ... 355.0 356.2 357.5 358.8\n",
      "  * member_id  (member_id) int64 1 2 3 4 5 6 7 8 9 ... 73 74 75 76 77 78 79 80\n",
      "  * slat       (slat) float32 -89.53 -88.59 -87.64 -86.7 ... 87.64 88.59 89.53\n",
      "  * slon       (slon) float32 -0.625 0.625 1.875 3.125 ... 355.6 356.9 358.1\n",
      "  * time       (time) datetime64[ns] 2011-01-03 ... 2019-12-31T18:00:00\n",
      "Data variables:\n",
      "    US         (member_id, time, lev, slat, lon) float64 dask.array<chunksize=(10, 30, 32, 32, 32), meta=np.ndarray>\n",
      "Attributes:\n",
      "    creation_date:   YYYY MM DD HH MM SS = 2019 07 10 01 31 17\n",
      "    model:           CAM\n",
      "    model_revdate:   $Date: 2019-03-26 09:18:06 -0600 (Tue, 26 Mar 2019) $\n",
      "    model_revision:  $Revision: 13074 $\n",
      "    dataset_id:      ds345.0\n",
      "    dataset_title:   DART Reanalysis\n",
      "    experiment_id:   Reanalysis\n",
      "    institution_id:  NCAR RDA\n",
      "    zarr-version:    1.0\n",
      "\n",
      "\n",
      "/glade/scratch/bonnland/DART/ds345.0/zarr-publish/CLDICE.zarr\n",
      "<xarray.Dataset>\n",
      "Dimensions:    (ilev: 33, lat: 192, lev: 32, lon: 288, member_id: 80, slat: 191, slon: 288, time: 685)\n",
      "Coordinates:\n",
      "  * ilev       (ilev) float32 2.255 5.032 10.16 18.56 ... 967.5 985.1 1e+03\n",
      "  * lat        (lat) float32 -90.0 -89.06 -88.12 -87.17 ... 88.12 89.06 90.0\n",
      "  * lev        (lev) float32 3.643 7.595 14.36 24.61 ... 936.2 957.5 976.3 992.6\n",
      "  * lon        (lon) float32 0.0 1.25 2.5 3.75 5.0 ... 355.0 356.2 357.5 358.8\n",
      "  * member_id  (member_id) int64 1 2 3 4 5 6 7 8 9 ... 73 74 75 76 77 78 79 80\n",
      "  * slat       (slat) float32 -89.53 -88.59 -87.64 -86.7 ... 87.64 88.59 89.53\n",
      "  * slon       (slon) float32 -0.625 0.625 1.875 3.125 ... 355.6 356.9 358.1\n",
      "  * time       (time) datetime64[ns] 2011-01-03 ... 2019-12-31T18:00:00\n",
      "Data variables:\n",
      "    CLDICE     (member_id, time, lev, lat, lon) float64 dask.array<chunksize=(10, 30, 32, 32, 32), meta=np.ndarray>\n",
      "Attributes:\n",
      "    creation_date:   YYYY MM DD HH MM SS = 2019 07 10 01 31 17\n",
      "    model:           CAM\n",
      "    model_revdate:   $Date: 2019-03-26 09:18:06 -0600 (Tue, 26 Mar 2019) $\n",
      "    model_revision:  $Revision: 13074 $\n",
      "    dataset_id:      ds345.0\n",
      "    dataset_title:   DART Reanalysis\n",
      "    experiment_id:   Reanalysis\n",
      "    institution_id:  NCAR RDA\n",
      "    zarr-version:    1.0\n",
      "\n",
      "\n",
      "/glade/scratch/bonnland/DART/ds345.0/zarr-publish/TSA.zarr\n",
      "<xarray.Dataset>\n",
      "Dimensions:    (lat: 192, lon: 288, member_id: 80, time: 11687)\n",
      "Coordinates:\n",
      "  * lat        (lat) float32 -90.0 -89.06 -88.12 -87.17 ... 88.12 89.06 90.0\n",
      "  * lon        (lon) float32 0.0 1.25 2.5 3.75 5.0 ... 355.0 356.2 357.5 358.8\n",
      "  * member_id  (member_id) int64 1 2 3 4 5 6 7 8 9 ... 73 74 75 76 77 78 79 80\n",
      "  * time       (time) datetime64[ns] 2012-01-01T06:00:00 ... 2019-12-31T18:00:00\n",
      "Data variables:\n",
      "    TSA        (member_id, time, lat, lon) float32 dask.array<chunksize=(40, 200, 32, 32), meta=np.ndarray>\n",
      "Attributes: (12/16)\n",
      "    Initial_conditions_dataset:           f.e21.FHIST_BGC.f09_025.CAM6assim.0...\n",
      "    PFT_physiological_constants_dataset:  clm5_params.c171117.nc\n",
      "    Surface_dataset:                      surfdata_0.9x1.25_78pfts_CMIP6_simy...\n",
      "    case_id:                              f.e21.FHIST_BGC.f09_025.CAM6assim.011\n",
      "    cft:                                  {\"cft_tropical_soybean\": 63, \"cft_i...\n",
      "    comment:                              NOTE: None of the variables are wei...\n",
      "    ...                                   ...\n",
      "    institution_id:                       NCAR RDA\n",
      "    ltype:                                {\"ltype_UNUSED\": 3, \"ltype_landice_...\n",
      "    source:                               Community Land Model CLM4.0\n",
      "    time_period_freq:                     hour_6\n",
      "    version:                              release-cesm2.1.0-1-gdab62ed\n",
      "    zarr-version:                         1.0\n",
      "\n",
      "\n",
      "/glade/scratch/bonnland/DART/ds345.0/zarr-publish/EFLX_LH_TOT.zarr\n",
      "<xarray.Dataset>\n",
      "Dimensions:      (lat: 192, lon: 288, member_id: 80, time: 11687)\n",
      "Coordinates:\n",
      "  * lat          (lat) float32 -90.0 -89.06 -88.12 -87.17 ... 88.12 89.06 90.0\n",
      "  * lon          (lon) float32 0.0 1.25 2.5 3.75 5.0 ... 355.0 356.2 357.5 358.8\n",
      "  * member_id    (member_id) int64 1 2 3 4 5 6 7 8 9 ... 73 74 75 76 77 78 79 80\n",
      "  * time         (time) datetime64[ns] 2012-01-01T06:00:00 ... 2019-12-31T18:...\n",
      "Data variables:\n",
      "    EFLX_LH_TOT  (member_id, time, lat, lon) float32 dask.array<chunksize=(40, 200, 32, 32), meta=np.ndarray>\n",
      "Attributes: (12/16)\n",
      "    Initial_conditions_dataset:           f.e21.FHIST_BGC.f09_025.CAM6assim.0...\n",
      "    PFT_physiological_constants_dataset:  clm5_params.c171117.nc\n",
      "    Surface_dataset:                      surfdata_0.9x1.25_78pfts_CMIP6_simy...\n",
      "    case_id:                              f.e21.FHIST_BGC.f09_025.CAM6assim.011\n",
      "    cft:                                  {\"cft_tropical_soybean\": 63, \"cft_i...\n",
      "    comment:                              NOTE: None of the variables are wei...\n",
      "    ...                                   ...\n",
      "    institution_id:                       NCAR RDA\n",
      "    ltype:                                {\"ltype_UNUSED\": 3, \"ltype_landice_...\n",
      "    source:                               Community Land Model CLM4.0\n",
      "    time_period_freq:                     hour_6\n",
      "    version:                              release-cesm2.1.0-1-gdab62ed\n",
      "    zarr-version:                         1.0\n",
      "\n",
      "\n",
      "/glade/scratch/bonnland/DART/ds345.0/zarr-publish/T.zarr\n",
      "<xarray.Dataset>\n",
      "Dimensions:    (ilev: 33, lat: 192, lev: 32, lon: 288, member_id: 80, slat: 191, slon: 288, time: 685)\n",
      "Coordinates:\n",
      "  * ilev       (ilev) float32 2.255 5.032 10.16 18.56 ... 967.5 985.1 1e+03\n",
      "  * lat        (lat) float32 -90.0 -89.06 -88.12 -87.17 ... 88.12 89.06 90.0\n",
      "  * lev        (lev) float32 3.643 7.595 14.36 24.61 ... 936.2 957.5 976.3 992.6\n",
      "  * lon        (lon) float32 0.0 1.25 2.5 3.75 5.0 ... 355.0 356.2 357.5 358.8\n",
      "  * member_id  (member_id) int64 1 2 3 4 5 6 7 8 9 ... 73 74 75 76 77 78 79 80\n",
      "  * slat       (slat) float32 -89.53 -88.59 -87.64 -86.7 ... 87.64 88.59 89.53\n",
      "  * slon       (slon) float32 -0.625 0.625 1.875 3.125 ... 355.6 356.9 358.1\n",
      "  * time       (time) datetime64[ns] 2011-01-03 ... 2019-12-31T18:00:00\n",
      "Data variables:\n",
      "    T          (member_id, time, lev, lat, lon) float64 dask.array<chunksize=(10, 30, 32, 32, 32), meta=np.ndarray>\n",
      "Attributes:\n",
      "    creation_date:   YYYY MM DD HH MM SS = 2019 07 10 01 31 17\n",
      "    model:           CAM\n",
      "    model_revdate:   $Date: 2019-03-26 09:18:06 -0600 (Tue, 26 Mar 2019) $\n",
      "    model_revision:  $Revision: 13074 $\n",
      "    dataset_id:      ds345.0\n",
      "    dataset_title:   DART Reanalysis\n",
      "    experiment_id:   Reanalysis\n",
      "    institution_id:  NCAR RDA\n",
      "    zarr-version:    1.0\n",
      "\n",
      "\n",
      "/glade/scratch/bonnland/DART/ds345.0/zarr-publish/ER.zarr\n",
      "<xarray.Dataset>\n",
      "Dimensions:    (lat: 192, lon: 288, member_id: 80, time: 11687)\n",
      "Coordinates:\n",
      "  * lat        (lat) float32 -90.0 -89.06 -88.12 -87.17 ... 88.12 89.06 90.0\n",
      "  * lon        (lon) float32 0.0 1.25 2.5 3.75 5.0 ... 355.0 356.2 357.5 358.8\n",
      "  * member_id  (member_id) int64 1 2 3 4 5 6 7 8 9 ... 73 74 75 76 77 78 79 80\n",
      "  * time       (time) datetime64[ns] 2012-01-01T06:00:00 ... 2019-12-31T18:00:00\n",
      "Data variables:\n",
      "    ER         (member_id, time, lat, lon) float32 dask.array<chunksize=(40, 200, 32, 32), meta=np.ndarray>\n",
      "Attributes: (12/16)\n",
      "    Initial_conditions_dataset:           f.e21.FHIST_BGC.f09_025.CAM6assim.0...\n",
      "    PFT_physiological_constants_dataset:  clm5_params.c171117.nc\n",
      "    Surface_dataset:                      surfdata_0.9x1.25_78pfts_CMIP6_simy...\n",
      "    case_id:                              f.e21.FHIST_BGC.f09_025.CAM6assim.011\n",
      "    cft:                                  {\"cft_tropical_soybean\": 63, \"cft_i...\n",
      "    comment:                              NOTE: None of the variables are wei...\n",
      "    ...                                   ...\n",
      "    institution_id:                       NCAR RDA\n",
      "    ltype:                                {\"ltype_UNUSED\": 3, \"ltype_landice_...\n",
      "    source:                               Community Land Model CLM4.0\n",
      "    time_period_freq:                     hour_6\n",
      "    version:                              release-cesm2.1.0-1-gdab62ed\n",
      "    zarr-version:                         1.0\n",
      "\n",
      "\n",
      "/glade/scratch/bonnland/DART/ds345.0/zarr-publish/CLDLIQ.zarr\n",
      "<xarray.Dataset>\n",
      "Dimensions:    (ilev: 33, lat: 192, lev: 32, lon: 288, member_id: 80, slat: 191, slon: 288, time: 685)\n",
      "Coordinates:\n",
      "  * ilev       (ilev) float32 2.255 5.032 10.16 18.56 ... 967.5 985.1 1e+03\n",
      "  * lat        (lat) float32 -90.0 -89.06 -88.12 -87.17 ... 88.12 89.06 90.0\n",
      "  * lev        (lev) float32 3.643 7.595 14.36 24.61 ... 936.2 957.5 976.3 992.6\n",
      "  * lon        (lon) float32 0.0 1.25 2.5 3.75 5.0 ... 355.0 356.2 357.5 358.8\n",
      "  * member_id  (member_id) int64 1 2 3 4 5 6 7 8 9 ... 73 74 75 76 77 78 79 80\n",
      "  * slat       (slat) float32 -89.53 -88.59 -87.64 -86.7 ... 87.64 88.59 89.53\n",
      "  * slon       (slon) float32 -0.625 0.625 1.875 3.125 ... 355.6 356.9 358.1\n",
      "  * time       (time) datetime64[ns] 2011-01-03 ... 2019-12-31T18:00:00\n",
      "Data variables:\n",
      "    CLDLIQ     (member_id, time, lev, lat, lon) float64 dask.array<chunksize=(10, 30, 32, 32, 32), meta=np.ndarray>\n",
      "Attributes:\n",
      "    DART_creation_date:  YYYY MM DD HH MM SS = 2019 07 10 01 31 17\n",
      "    creation_date:       YYYY MM DD HH MM SS = 2019 07 10 01 31 17\n",
      "    model:               CAM\n",
      "    model_revdate:       $Date: 2019-03-26 09:18:06 -0600 (Tue, 26 Mar 2019) $\n",
      "    model_revision:      $Revision: 13074 $\n",
      "    dataset_id:          ds345.0\n",
      "    dataset_title:       DART Reanalysis\n",
      "    experiment_id:       Reanalysis\n",
      "    institution_id:      NCAR RDA\n",
      "    zarr-version:        1.0\n"
     ]
    }
   ],
   "source": [
    "# Open each output dataset to confirm it was created properly.\n",
    "\n",
    "zarr_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jul  8 16:42:11 MDT 2021\n"
     ]
    }
   ],
   "source": [
    "!date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
