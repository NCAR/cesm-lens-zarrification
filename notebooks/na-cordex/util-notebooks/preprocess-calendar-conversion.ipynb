{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import shutil \n",
    "import os\n",
    "\n",
    "import intake\n",
    "import cftime\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calendar Conversion functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for converting single date objects from one type to another.\n",
    "\n",
    "def convert_to_noleap(cftime360_obj, datemap):\n",
    "    ''' Convert Date from 360 Day to NoLeap'''\n",
    "    newdate = datemap[cftime360_obj.dayofyr - 1]\n",
    "    converted = cftime.DatetimeNoLeap(year=cftime360_obj.year, month=newdate.month, day=newdate.day)\n",
    "    return converted\n",
    "\n",
    "def convert_to_gregorian(cftime_noleap_obj):\n",
    "    ''' Convert Date from NoLeap to Gregorian '''\n",
    "    converted = cftime.DatetimeGregorian(year=cftime_noleap_obj.year, month=cftime_noleap_obj.month, day=cftime_noleap_obj.day)\n",
    "    return converted\n",
    "\n",
    "def convert_hour(time_obj, hour_of_day):\n",
    "    ''' Convert date object to Gregorian and explicitly set the hour of day.'''\n",
    "    time_obj = cftime.DatetimeGregorian(year=time_obj.year, month=time_obj.month, day=time_obj.day, hour=hour_of_day, minute=0, second=0)\n",
    "    return time_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datemap_360_to_noleap():\n",
    "    ''' Return an array of dates mapping days from the 360-Day calendar to the No-Leap calendar. '''\n",
    "\n",
    "    # Choose any year with 365 days. \n",
    "    dummy_year = 1999\n",
    "\n",
    "    # These are the days of the year that will be missing on the time axis for each year.\n",
    "    # The goal is to spread missing dates out evenly over each year.\n",
    "    #\n",
    "    # Modify specific dates as desired. \n",
    "    missing_dates = [date(dummy_year, 1, 31),\n",
    "                     date(dummy_year, 3, 31),\n",
    "                     date(dummy_year, 5, 31),\n",
    "                     date(dummy_year, 8, 31),\n",
    "                     date(dummy_year, 10, 31),]\n",
    "    \n",
    "    day_one = date(dummy_year, 1, 1)\n",
    "    missing_dates_indexes = [(day - day_one).days + 1 for day in missing_dates] \n",
    "    missing_dates_indexes\n",
    "\n",
    "    datemap_indexes = np.setdiff1d(np.arange(365), missing_dates_indexes)\n",
    "    datemap_indexes\n",
    "\n",
    "    dates = pd.date_range(f'1/1/{dummy_year}', f'12/31/{dummy_year}')\n",
    "    assert(len(dates) == 365)\n",
    "    \n",
    "    date_map = dates[datemap_indexes]\n",
    "    assert(len(date_map) == 360)\n",
    "    \n",
    "    # Check to make sure February 29 is not a date in the resulting map.\n",
    "    #is_leap_day = [(d.month == 2) and (d.day == 29) for d in date_map]\n",
    "    #print(is_leap_day)\n",
    "    #assert(not any(is_leap_day))\n",
    "    return date_map\n",
    "\n",
    "\n",
    "# Create a global map for moving days of the year to other days of the year.\n",
    "datemap_global = get_datemap_360_to_noleap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(ds):\n",
    "    \"\"\"This function gets called on each original dataset before concatenation.\n",
    "       Convert all dataset calendars to Gregorian.  \n",
    "       For now, also drop other data variables, like time bounds, until we get things looking good.\n",
    "    \"\"\"\n",
    "\n",
    "    # Print dataset title for debug purposes\n",
    "    #print(ds.attrs['title'])\n",
    "    #print(f'ds.time.attrs = {ds.time.attrs}')\n",
    "    #print(f'ds.time.encoding = {ds.time.encoding}')\n",
    "\n",
    "    attrs = ds.time.attrs\n",
    "    encoding = ds.time.encoding\n",
    "    bounds_name = ds.time.attrs['bounds']\n",
    "    \n",
    "    ds_fixed = ds\n",
    "    #\"\"\"Drop all unneeded variables and coordinates\"\"\"\n",
    "    #vars_to_drop = [vname for vname in ds.data_vars if vname not in variables]\n",
    "    #coord_vars = [vname for vname in ds.data_vars if 'time' not in ds[vname].dims or 'bnd' in vname]\n",
    "    #ds_fixed = ds.set_coords(coord_vars)\n",
    "    #data_vars_dims = []\n",
    "    #for data_var in ds_fixed.data_vars:\n",
    "    #    data_vars_dims.extend(list(ds_fixed[data_var].dims))\n",
    "    #coords_to_drop = [coord for coord in ds_fixed.coords if coord not in data_vars_dims]\n",
    "    #grid_vars = list(set(vars_to_drop + coords_to_drop) - set(['time', 'time_bound']))\n",
    "    #ds_fixed = ds_fixed.drop(grid_vars)\n",
    "    #if 'history' in ds_fixed.attrs:\n",
    "    #    del ds_fixed.attrs['history']\n",
    "    \n",
    "    # Print some diagnostic information on the dataset.\n",
    "    #print_ds_info(ds, 'tasmax')\n",
    "    \n",
    "    # Test for calendar type xarray found when it loaded the dataset.\n",
    "    time_type = f'{type(ds.time.values[0])}'\n",
    "    has_360_day_calendar = \"Datetime360Day\" in time_type\n",
    "    has_noleap_calendar = \"DatetimeNoLeap\" in time_type\n",
    "    \n",
    "    # Extract the time_bnds variable for conversion\n",
    "    bnds = ds_fixed[bounds_name].values\n",
    "\n",
    "    if has_360_day_calendar:\n",
    "        print(f'Found 360 day calendar; converting dates to NoLeap, then date types to Gregorian.\\n')\n",
    "        ds_fixed['time'] = [convert_to_noleap(t, datemap_global) for t in ds_fixed.time.values]\n",
    "        ds_fixed['time'] = [convert_to_gregorian(t) for t in ds_fixed.time.values]\n",
    "\n",
    "        bnds = [[convert_to_noleap(col, datemap_global) for col in row] for row in bnds]\n",
    "        bnds = [[convert_to_gregorian(col) for col in row] for row in bnds]\n",
    "        #ds_fixed = convert_dataset_noleap_to_gregorian(ds_fixed)\n",
    "\n",
    "    # Convert any NoLeap calendar to the Gregorian calendar.\n",
    "    elif has_noleap_calendar:\n",
    "        ds_fixed['time'] = [convert_to_gregorian(t) for t in ds_fixed.time.values]\n",
    "        bnds = [[convert_to_gregorian(col) for col in row] for row in bnds]\n",
    "        #ds_fixed = convert_dataset_noleap_to_gregorian(ds_fixed)\n",
    "\n",
    "    # Change time of day to noon for all time axis points.\n",
    "    #print(ds_fixed.time.values.shape)\n",
    "    ds_fixed['time'] = [convert_hour(t, 12) for t in ds_fixed.time.values]\n",
    "    bnds = [[convert_hour(col, 0) for col in row] for row in bnds]\n",
    "    ds_fixed[bounds_name] = (('time', 'bnds'), bnds)\n",
    "    \n",
    "    # Convert CFTimeIndex to Pandas DateTimeIndex\n",
    "    if type(ds_fixed.time.indexes['time'] == 'Index'):\n",
    "        print('found Index object; converting to CFTimeIndex object.\\n')\n",
    "        datetimeindex = xr.CFTimeIndex(ds_fixed.time.indexes['time']).to_datetimeindex()\n",
    "        ds.assign_coords(time = datetimeindex)\n",
    "        \n",
    "    ds.time.attrs = attrs\n",
    "    ds.time.encoding = encoding\n",
    "    ds = ds.set_coords([bounds_name])\n",
    "\n",
    "    return ds_fixed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Preprocessing Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's safer to use a underscore separator, because NA-CORDEX grids have dashes.\n",
    "field_separator = '_'\n",
    "col = intake.open_esm_datastore(\"./glade-na-cordex-bonnland.json\", sep=field_separator)\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset to a single target Zarr store.\n",
    "subset = col.search(variable='tasmax', scenario='hist', frequency='day', grid='NAM-22i', biascorrection='raw')\n",
    "subset.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in subset.df['path']:\n",
    "    outFilePath = path.replace('/glade/collections/cdg/data/cordex/data','/glade/scratch/bonnland/na-cordex/netcdf')\n",
    "    \n",
    "    # If output file path doesn't yet exist, open the dataset, preprocess it, and save to the outFilePath.\n",
    "    if not os.path.exists(outFilePath):\n",
    "        ds = xr.open_dataset(path, use_cftime=True, chunks={'time': 500})\n",
    "        ds_fixed = preprocess(ds)\n",
    "        ds_fixed.to_netcdf(outFilePath)\n",
    "        print(f'Created file {outFilePath.split(\"/\")[-1]}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Testing Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testFile = subset.df['path'][0]\n",
    "testFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(testFile, use_cftime=True, chunks={'time': 500})\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_fixed = preprocess(ds)\n",
    "ds_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outFilePath = testFile.replace('/glade/collections/cdg/data/cordex/data','/glade/scratch/bonnland/na-cordex/netcdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.to_netcdf(outFilePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_check = xr.open_dataset(outFilePath, decode_cf=True)\n",
    "ds_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run These Cells for Dask Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "from ncar_jobqueue import NCARCluster\n",
    "\n",
    "# Processes is processes PER CORE.\n",
    "cluster = NCARCluster(cores=20, processes=1, memory='109GB', project='STDD0003')\n",
    "cluster.scale(jobs=20)\n",
    "\n",
    "from distributed import Client\n",
    "from distributed.utils import format_bytes\n",
    "client = Client(cluster)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
